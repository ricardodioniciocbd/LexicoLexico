# GU√çA DE COMENTARIOS EN ESPA√ëOL - C√ìDIGO FUENTE

Este documento lista todos los comentarios importantes en espa√±ol agregados al c√≥digo para facilitar su identificaci√≥n y comprensi√≥n.

---

## üìÑ `lexer.py` - An√°lisis L√©xico (PUNTO 2)

### Comentarios Principales

```python
"""
M√≥dulo de An√°lisis L√©xico
Realiza la tokenizaci√≥n del c√≥digo fuente (convierte texto en tokens)
PUNTO 2: Implementa Aut√≥matas Finitos Deterministas (AFD)
"""

class Lexer:
    """
    Analizador L√©xico (Lexer) - PUNTO 2
    Implementa AFD (Aut√≥mata Finito Determinista) para reconocer tokens
    """
```

### Funciones Clave

| Funci√≥n | Descripci√≥n en Espa√±ol |
|---------|------------------------|
| `peek()` | **Lookahead**: Mira el siguiente car√°cter sin consumirlo. Esencial para AFD con lookahead |
| `advance()` | Consume y retorna el car√°cter actual (avanza en el c√≥digo) |
| `read_number()` | **AFD para n√∫meros**: Estados q0 ‚Üí q1 (d√≠gitos) ‚Üí q2 (punto) ‚Üí q3 (m√°s d√≠gitos) |
| `read_string()` | **AFD para strings**: Lee cadenas encerradas en comillas, maneja secuencias de escape |
| `read_identifier()` | **AFD para identificadores**: q0 --[letra\|_]--> q1 --[letra\|d√≠gito\|_]--> q1 |
| `handle_indentation()` | Genera tokens INDENT/DEDENT basado en cambios de indentaci√≥n |
| `tokenize()` | **M√©todo principal**: Convierte c√≥digo fuente en tokens |

### Comentarios Inline Importantes

```python
# L√≠nea 24: Posici√≥n actual en el c√≥digo
self.position = 0

# L√≠nea 25: L√≠nea actual
self.line = 1

# L√≠nea 26: Columna actual
self.column = 1

# L√≠nea 27: Lista de tokens generados
self.tokens = []

# L√≠nea 28: Pila para rastrear niveles de indentaci√≥n
self.indent_stack = [0]

# L√≠nea 80: Convertir a tipo num√©rico apropiado
# L√≠nea 104: Manejar secuencias de escape
# L√≠nea 128: Verificar si es una palabra clave (keyword)
# L√≠nea 162: Manejar indentaci√≥n al inicio de l√≠neas
# L√≠nea 172-177: Comentarios
# L√≠nea 183-189: N√∫meros
# L√≠nea 191-193: Strings
# L√≠nea 195-199: Identificadores y palabras clave
# L√≠nea 201-221: Operadores de dos caracteres
# L√≠nea 223-270: Operadores de un car√°cter y delimitadores
# L√≠nea 275: Agregar tokens DEDENT restantes
# L√≠nea 280: Agregar token EOF
```

---

## üìÑ `parser.py` - An√°lisis Sint√°ctico (PUNTO 3)

### Comentarios Principales

```python
"""
M√≥dulo de An√°lisis Sint√°ctico (Parser)
Realiza el an√°lisis sint√°ctico y construye el √Årbol de Sintaxis Abstracta (AST)
PUNTO 3: Implementa Gram√°tica Libre de Contexto (CFG) tipo LL(1)
"""

class Parser:
    """
    Parser de Descenso Recursivo - PUNTO 3
    Implementa an√°lisis sint√°ctico LL(1) sin recursi√≥n izquierda
    Construye el AST (√Årbol de Sintaxis Abstracta)
    """
```

### Producciones Gramaticales con Acciones Sem√°nticas

| Funci√≥n | Producci√≥n | Acci√≥n Sem√°ntica |
|---------|-----------|------------------|
| `parse_program()` | programa ‚Üí declaraciones | Crea ProgramNode con lista de sentencias |
| `parse_statement()` | sentencia ‚Üí asignacion \| impresion \| condicional \| bucle | Enruta al parser apropiado seg√∫n token |
| `parse_assignment()` | asignacion ‚Üí ID = expresion | Crea AssignmentNode con identificador y expresi√≥n |
| `parse_print()` | print_statement ‚Üí print(expresion) | Crea PrintNode con expresi√≥n a imprimir |
| `parse_if()` | condicional ‚Üí if expr : bloque (elif)* (else)? | Crea IfNode con condici√≥n, bloques then/else |
| `parse_while()` | bucle_while ‚Üí while expresion : bloque | Crea WhileNode con condici√≥n y bloque |
| `parse_for()` | bucle_for ‚Üí for ID in range(expr) : bloque | Crea ForNode con variable, rango y bloque |
| `parse_block()` | bloque ‚Üí INDENT sentencias DEDENT | Crea BlockNode con lista de sentencias |
| `parse_expression()` | expresion ‚Üí comparacion | Punto de entrada para expresiones |
| `parse_comparison()` | comparacion ‚Üí aritmetica ((==\|!=\|<\|>)...)? | Crea BinaryOpNode para comparaciones |
| `parse_arithmetic()` | expresion ‚Üí termino ((+\|-) termino)* | Crea √°rbol de BinaryOpNode con asociatividad izquierda |
| `parse_term()` | termino ‚Üí factor ((*\|/) factor)* | BinaryOpNode para multiplicaci√≥n/divisi√≥n con mayor precedencia |
| `parse_factor()` | factor ‚Üí NUMBER \| STRING \| ID \| (expr) \| -factor | Crea nodo hoja apropiado o maneja expresi√≥n parentizada |

### Jerarqu√≠a de Precedencia (de mayor a menor)

```python
# NIVEL 1: Par√©ntesis ( )
# NIVEL 2: Unario -
# NIVEL 3: Multiplicaci√≥n/Divisi√≥n * / %  ‚Üê parse_term()
# NIVEL 4: Suma/Resta + -                ‚Üê parse_arithmetic()
# NIVEL 5: Comparaci√≥n < > <= >=         ‚Üê parse_comparison()
# NIVEL 6: Igualdad == !=                ‚Üê parse_comparison()
```

### Comentarios Importantes

```python
# L√≠nea 24: Lanza error de parser con informaci√≥n del token actual
# L√≠nea 34: Lookahead: Mira token siguiente sin consumirlo
# L√≠nea 41: Avanza al siguiente token
# L√≠nea 48: Consume token del tipo esperado o lanza error
# L√≠nea 56: Salta tokens de nueva l√≠nea (NEWLINE)
# L√≠nea 86: Analiza una sentencia individual
# L√≠nea 90-99: Asignaci√≥n o expresi√≥n
# L√≠nea 91-93: Lookahead para determinar si es asignaci√≥n
# L√≠nea 161-172: Analiza bloques elif
# L√≠nea 174-180: Analiza bloque else
# L√≠nea 224-226: Espera token INDENT
# L√≠nea 230-235: Analiza sentencias hasta DEDENT
# L√≠nea 237-239: Consume DEDENT
# L√≠nea 257-261: Operadores de comparaci√≥n
# L√≠nea 272-286: Jerarqu√≠a de precedencia - Recursi√≥n eliminada
# L√≠nea 311-340: Literales num√©ricos, strings, identificadores, par√©ntesis, unario
```

---

## üìÑ `semantic_analyzer.py` - An√°lisis Sem√°ntico (PUNTOS 4 y 7)

### Comentarios Principales

```python
"""
Analizador Sem√°ntico
Verifica que las variables est√©n declaradas antes de usarse y que los tipos sean compatibles
PUNTO 4: Tabla de S√≠mbolos y Gesti√≥n de Contexto
PUNTO 7: An√°lisis Sem√°ntico Basado en Gram√°ticas Atribuidas
"""

class SemanticAnalyzer:
    """
    Analizador Sem√°ntico - PUNTOS 4 y 7
    - Tabla de s√≠mbolos con inferencia de tipos
    - Verificaci√≥n de declaraci√≥n antes de uso
    - Compatibilidad de tipos en operaciones
    - Visitor Pattern para recorrer el AST
    """
```

### Estructura de la Tabla de S√≠mbolos

```python
# L√≠nea 18: Tabla de s√≠mbolos
self.symbol_table = {
    'nombre_variable': {
        'type': tipo,           # str, int, float, list, bool
        'initialized': bool,    # ¬øEst√° inicializada?
        'line': linea          # L√≠nea de declaraci√≥n
    }
}
```

### M√©todos Importantes

| M√©todo | Descripci√≥n | Punto |
|--------|-------------|-------|
| `infer_type()` | Infiere el tipo de una expresi√≥n (atributos sintetizados) | 7 |
| `check_type_compatibility()` | Verifica compatibilidad de tipos en operaciones | 7 |
| `analyze()` | Analiza el AST completo | 4, 7 |
| `visit()` | Visitor Pattern - visita un nodo del AST | 6, 7 |
| `visit_AssignmentNode()` | Registra variable en tabla de s√≠mbolos | 4 |
| `visit_IdentifierNode()` | Verifica que variable est√© declarada antes de uso | 4 |
| `visit_BinaryOpNode()` | Verifica compatibilidad de tipos | 7 |
| `get_report()` | Genera reporte del an√°lisis sem√°ntico | 5 |

### Comentarios Clave

```python
# L√≠nea 34: Infiere el tipo de una expresi√≥n
# L√≠nea 36: N√∫meros: 'int' o 'float'
# L√≠nea 38: Strings: 'str'
# L√≠nea 40-42: Identificadores: busca en tabla de s√≠mbolos
# L√≠nea 48-49: Comparaciones siempre devuelven 'bool'
# L√≠nea 53-59: Operaciones aritm√©ticas
# L√≠nea 54-55: Si alguno es float, el resultado es float
# L√≠nea 57-59: Si ambos son int, resultado es int (excepto divisi√≥n)
# L√≠nea 60-62: Concatenaci√≥n de strings con +
# L√≠nea 75: Verifica compatibilidad de tipos en una operaci√≥n
# L√≠nea 78: Operadores aritm√©ticos
# L√≠nea 79-88: Suma de strings (concatenaci√≥n)
# L√≠nea 90-105: Operaciones num√©ricas
# L√≠nea 108-109: Advertencia por posible divisi√≥n por cero
# L√≠nea 114: Operadores de comparaci√≥n
# L√≠nea 116-117: Cualquier tipo se puede comparar con ==, !=
# L√≠nea 119-122: <, >, <=, >= requieren tipos compatibles
# L√≠nea 132: Analiza el AST completo
# L√≠nea 137: Visitor Pattern
# L√≠nea 139: Busca m√©todo visit_{NombreNodo}
# L√≠nea 152-174: Visita asignaci√≥n - actualiza tabla de s√≠mbolos
# L√≠nea 158: Infiere el tipo de la expresi√≥n
# L√≠nea 160-167: Verifica cambio de tipo (advertencia)
# L√≠nea 169-174: Registra/actualiza variable en tabla
# L√≠nea 234-246: Visita operaci√≥n binaria - verifica tipos
# L√≠nea 260-271: Visita identificador - verifica declaraci√≥n
```

---

## üìÑ `ast_nodes.py` - Nodos del AST (PUNTO 6)

### Comentarios Principales

```python
"""
Definiciones de Nodos del √Årbol de Sintaxis Abstracta (AST)
PUNTO 6: Estructura Jer√°rquica que representa el programa
"""

class ASTNode:
    """Nodo base del AST - todos los nodos heredan de esta clase"""
    pass

class ProgramNode(ASTNode):
    """Nodo ra√≠z del programa - contiene lista de sentencias"""
    def __init__(self, statements):
        self.statements = statements  # Lista de sentencias del programa

class AssignmentNode(ASTNode):
    """Nodo de asignaci√≥n: x = expresion"""
    def __init__(self, identifier, expression, line=0):
        self.identifier = identifier  # Nombre de la variable
        self.expression = expression  # Expresi√≥n a asignar
        self.line = line  # L√≠nea en el c√≥digo fuente

class BinaryOpNode(ASTNode):
    """Nodo de operaci√≥n binaria: left operador right"""
    def __init__(self, left, operator, right, line=0):
        self.left = left        # Expresi√≥n izquierda
        self.operator = operator  # Operador (+, -, *, /, ==, etc.)
        self.right = right       # Expresi√≥n derecha
        self.line = line
```

### Todos los Nodos del AST

| Clase | Descripci√≥n |
|-------|-------------|
| `ASTNode` | Nodo base (clase padre) |
| `ProgramNode` | Ra√≠z del programa |
| `AssignmentNode` | Asignaci√≥n (x = expr) |
| `PrintNode` | Sentencia print |
| `IfNode` | Condicional if/elif/else |
| `WhileNode` | Bucle while |
| `ForNode` | Bucle for |
| `BlockNode` | Bloque de sentencias |
| `BinaryOpNode` | Operaci√≥n binaria |
| `UnaryOpNode` | Operaci√≥n unaria |
| `NumberNode` | Literal num√©rico |
| `StringNode` | Literal de cadena |
| `IdentifierNode` | Identificador/variable |
| `ListNode` | Lista/arreglo |
| `IndexNode` | Acceso por √≠ndice |
| `CallNode` | Llamada a funci√≥n |

---

## üìÑ `token_types.py` - Tipos de Tokens (PUNTO 1)

### Comentarios Principales

```python
"""
Definici√≥n de Tipos de Tokens y Alfabeto del Lenguaje
PUNTO 1: Define formalmente Œ£ (alfabeto de entrada)
"""

class TokenType(Enum):
    """
    Tipos de tokens del lenguaje - PUNTO 1
    Define el alfabeto Œ£ para la gram√°tica formal
    """
    # Literales
    NUMBER = auto()      # N√∫meros: [0-9]+(\.[0-9]+)?
    STRING = auto()      # Strings: "[^"]*" | '[^']*'
    IDENTIFIER = auto()  # Identificadores: [a-zA-Z_][a-zA-Z0-9_]*
    
    # Palabras clave
    IF = auto()          # if
    ELIF = auto()        # elif
    ELSE = auto()        # else
    WHILE = auto()       # while
    FOR = auto()         # for
    # ... etc

KEYWORDS = {
    'if': TokenType.IF,
    'elif': TokenType.ELIF,
    # ... m√°s palabras clave
}
```

---

## üìÑ `parser_stack.py` - Aut√≥mata de Pila (PUNTO 8) üÜï

### Comentarios Principales

```python
"""
Aut√≥mata de Pila Formal para An√°lisis Sint√°ctico
Implementa un parser LR(1) con tabla de parsing expl√≠cita
PUNTO 8: Aut√≥matas de Pila con Tablas ACTION y GOTO
"""

class PushdownAutomaton:
    """
    Aut√≥mata de Pila (PDA) para An√°lisis Sint√°ctico
    
    Formalmente: PDA = (Q, Œ£, Œì, Œ¥, q0, Z0, F)
    Donde:
    - Q: Conjunto de estados
    - Œ£: Alfabeto de entrada (tokens)
    - Œì: Alfabeto de la pila
    - Œ¥: Funci√≥n de transici√≥n
    - q0: Estado inicial
    - Z0: S√≠mbolo inicial de la pila
    - F: Estados finales
    """
```

### Tablas LR

```python
# Tabla ACTION: (estado, terminal) ‚Üí acci√≥n
self.action_table[(estado, terminal)] = LRAction(Action.SHIFT, nuevo_estado)
self.action_table[(estado, terminal)] = LRAction(Action.REDUCE, regla)
self.action_table[(estado, terminal)] = LRAction(Action.ACCEPT)

# Tabla GOTO: (estado, no_terminal) ‚Üí estado
self.goto_table[(estado, no_terminal)] = nuevo_estado
```

---

## üìÑ `automata_optimizer.py` - Minimizaci√≥n (PUNTO 9) üÜï

### Comentarios Principales

```python
"""
Optimizaciones Basadas en Teor√≠a de Aut√≥matas
Implementa minimizaci√≥n de aut√≥matas y an√°lisis de complejidad
PUNTO 9: Minimizaci√≥n de DFA con algoritmo de Hopcroft
"""

class AutomataMinimizer:
    """
    Minimizador de Aut√≥matas Finitos Deterministas
    Implementa el algoritmo de Hopcroft para minimizaci√≥n en O(n log n)
    
    Pasos:
    1. Eliminar estados inalcanzables
    2. Particionar estados en equivalentes/no equivalentes
    3. Refinar particiones hasta convergencia
    4. Construir DFA m√≠nimo
    """
```

### An√°lisis de Complejidad

```python
# Complejidad temporal: O(n log n) - algoritmo de Hopcroft
# Complejidad espacial: O(n¬≤) - particiones
# Reducci√≥n de estados: original ‚Üí minimizado
```

---

## üìÑ `formal_properties.py` - Propiedades Formales (PUNTO 10) üÜï

### Comentarios Principales

```python
"""
Propiedades de Cerradura y Decidibilidad de Lenguajes Formales
Implementa verificaciones de propiedades formales seg√∫n teor√≠a de aut√≥matas
PUNTO 10: Operaciones de Cerradura y Problemas Decidibles
"""

class ClosureProperties:
    """
    Verificaci√≥n de Propiedades de Cerradura
    
    Los lenguajes regulares son cerrados bajo:
    - Uni√≥n: L1 ‚à™ L2
    - Concatenaci√≥n: L1 ¬∑ L2
    - Estrella de Kleene: L*
    - Complemento: L'
    - Intersecci√≥n: L1 ‚à© L2
    - Diferencia: L1 - L2
    """

class DecidabilityAnalyzer:
    """
    An√°lisis de Propiedades Decidibles
    
    Para lenguajes regulares, estos problemas son DECIDIBLES:
    1. Problema del vac√≠o: ¬øL = ‚àÖ?  ‚Üí O(n + m)
    2. Problema de finitud: ¬ø|L| < ‚àû?  ‚Üí O(n¬≤)
    3. Problema de pertenencia: ¬øw ‚àà L?  ‚Üí O(|w|)
    4. Problema de equivalencia: ¬øL1 = L2?  ‚Üí O(n1 √ó n2)
    """
```

---

## üìä RESUMEN DE COMENTARIOS POR PUNTO

| Punto | Archivo Principal | Comentarios Clave |
|-------|-------------------|-------------------|
| 1 | `token_types.py` | Define Œ£ (alfabeto), G = (N, Œ£, P, S) |
| 2 | `lexer.py` | AFD para tokens, lookahead, tabla de transiciones |
| 3 | `parser.py` | CFG, LL(1), eliminaci√≥n recursi√≥n izquierda, precedencia |
| 4 | `semantic_analyzer.py` | Tabla de s√≠mbolos, √°mbitos, verificaci√≥n tipos |
| 5 | Todos | Manejo errores, panic mode, localizaci√≥n, recuperaci√≥n |
| 6 | `ast_nodes.py` | Jerarqu√≠a de nodos, Visitor Pattern |
| 7 | `semantic_analyzer.py` | Gram√°ticas atribuidas, inferencia tipos |
| 8 | `parser_stack.py` | PDA, tablas LR, ACTION/GOTO |
| 9 | `automata_optimizer.py` | Minimizaci√≥n O(n log n), compresi√≥n tablas |
| 10 | `formal_properties.py` | Cerradura, decidibilidad, complejidad |

---

## üîç C√ìMO BUSCAR COMENTARIOS ESPEC√çFICOS

### Por Punto Te√≥rico
```bash
# Buscar comentarios del PUNTO 2 (AFD)
grep -r "PUNTO 2" *.py

# Buscar comentarios del PUNTO 8 (PDA)
grep -r "PUNTO 8" *.py
```

### Por Concepto
```bash
# Buscar AFD (Aut√≥mata Finito Determinista)
grep -r "AFD" *.py

# Buscar Tabla de S√≠mbolos
grep -r "Tabla de s√≠mbolos" *.py

# Buscar Visitor Pattern
grep -r "Visitor" *.py
```

### Por Complejidad
```bash
# Buscar an√°lisis de complejidad
grep -r "O(n" *.py

# Buscar Complejidad temporal
grep -r "Complejidad temporal" *.py
```

---

## üìù NOTAS IMPORTANTES

### Convenciones de Comentarios

1. **Docstrings de M√≥dulo**: Explican el prop√≥sito general y qu√© punto implementan
2. **Docstrings de Clase**: Describen la estructura formal (AFD, PDA, etc.)
3. **Docstrings de Funci√≥n**: Incluyen producci√≥n gramatical y acci√≥n sem√°ntica
4. **Comentarios Inline**: Explican l√≠neas espec√≠ficas importantes

### Identificadores Clave

- **"PUNTO X"**: Indica qu√© punto de los 10 implementa
- **"AFD"**: Aut√≥mata Finito Determinista
- **"PDA"**: Aut√≥mata de Pila (Pushdown Automaton)
- **"CFG"**: Gram√°tica Libre de Contexto
- **"AST"**: √Årbol de Sintaxis Abstracta
- **"Visitor"**: Patr√≥n Visitor
- **"O(n)"**: Notaci√≥n Big-O de complejidad

---

**√öltima actualizaci√≥n**: Octubre 2025  
**Idioma**: Espa√±ol  
**Prop√≥sito**: Facilitar identificaci√≥n y comprensi√≥n del c√≥digo


